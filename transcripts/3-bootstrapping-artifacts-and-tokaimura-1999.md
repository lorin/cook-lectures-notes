# 3. Bootstrapping, Artifacts, and Tokaimura, 1999

## Tokaimura

And we'll begin as we always do at the beginning of a seminar by asking about questions and concerns and things that have come up since the last time. Things about seminar two, where we talked about the Dryden Air Ontario crash, and also about some topics related to cognitive modeling. Or seminar one where we talked about Three Mile Island and human factors.

Is there anything in any of those, that background of any of the first two seminars that you've thought about or considered, or want to talk more about or ask questions about. I can take those now.

Wow, you guys are really smart.

So today we're going to talk about an accident at Tokaimura, which is in the Ibaraki prefecture, which is about a hundred miles outside of Tokyo. Tokaimura, is the name of a city that has in it, a small fuel reprocessing plant. The fuel reprocessing plant is there because Japan gets most of its electrical energy from nuclear power.

Japan has virtually no oil or gas reserves of its own. It must import all of its petroleum resources. So petroleum is very expensive there. And so they have invested very heavily in the nuclear fuel cycle. And unlike many other countries, they are signatories of the nuclear non-proliferation treaty, but they also process their own nuclear fuel, which means that they can process spent fuel from reactors.

And also process uranium to enrich it for purposes of running power reactors. They do not have a weapons program, but they do have all the other parts of the nuclear fuel cycle. What happened at Tokaimura was not only completely unexpected: it was impossible. It was the kind of accident that no one believed could possibly happen.

In fact, the plant was supposedly incapable of producing this kind of outcome. The outcome was a criticality accident, and to know what a criticality accident is we have to just stop for a moment and review a little bit of this stuff. You know this, but we'll review it just in the back. 

If you have a uranium nucleus, this can split into two smaller nuclei and release some energy: a gamma ray... a photon, and also release two other neutrons. The neutrons have no charge on them and they just float off. And one of the things that can cause this to fission like this is an incoming neutron. That is, if you put a neutron into this thing, a beam of neutrons, a neutron strikes this, it'll cause the nucleus to fission into two other nuclei, little smaller ones: krypton, and the other one, I don't remember. These themselves go off and what's left is this energy coming out and a couple of neutrons.

What you realize from this is that if this continues, this neutron can go on and split another nucleus into two nuclei, and it can release more energy and another two neutrons. And this neutron can go out and split another nucleus into two smaller nuclei and give off some energy and release two more neutrons. And what you can see is that every time you do one of these splits, you get twice the number of neutrons that you started with. So you have one going in here, you get two neutrons out. You fission another two nuclei, you get four neutrons out.

And so this in theory can keep on going. It's an exponential expansion, right? You're doubling every time. Each one of these steps doubles the number of neutrons. And so long as all these neutrons go on to participate in fissioning a reaction you'll get suddenly a huge amount of energy coming up. And this process happens very fast. It takes just small fractions of a nanosecond to make these reactions start to take place. So what you can get is if this goes on long enough is a huge release of energy very quickly. And that huge release of energy is called "criticality".

A criticality accident is one where you have this kind of reaction going on now. Why don't you have it happen all the time? Why isn't this going on all the time? You got a bunch of uranium sitting here, why isn't it doing this? And the answer is that for most uranium, particularly the stuff that we have a lot of, which is U-238, which is a kind of heavy molecule, it turns out that the neutrons that come out are moving fairly fast. They're zipping away from there. And because they zip away, they tend not to interact with other nuclei. And although there are uranium atoms inside a big chunk of U-238, if you had it here and you put a Geiger counter next to it, it would be radioactive. You could detect that there are decays occurring in there like this, but it never reaches criticality because the neutrons that are released, aren't going on to fission other atoms. You have to have this fissioning of other atoms to create the criticality. It turns out that's the big difference between U-238 and U-235. U-235 can catch these neutrons that are happening coming out here very quickly, and it catches them and fissions with them.

So if one of these comes out, one of these comes out in a lump of U-235, the chance of them fissioning is actually very high. This is what bombs are made out of. This is what powers nuclear reactors.

Actually, there's a mix of these two. Everywhere you go, there's some combination of these two different isotopes in any lump of uranium. Mostly it's U-238. So if you just went out and dug some out of the soil, 99% or more of it as U-238 and less than a percent is U-235. And if you want to make a bomb, you need, really, you need this stuff to be on the order of 80% enriched. 

And so that's what the Iranians are doing in in their facilities at the nuclear plants. They are taking U-238 and U-235, putting it in centrifuges, spinning it real fast. Because as it spins around, the U-238, which is heavier, goes out to the edge, whereas the U-235 stays more closer to the center and this stuff gets stripped off. And what they're left with is a little bit more U-235 than U-238. And if you put thousands of these centrifuges in a line, eventually you get pretty pure U-235 out, and that's what you need to make a bomb. 

Most nuclear reactors can use some sort of slightly enriched stuff. So instead of 99%, they might have 90% or 92% U-238 and say 8% U-235.  That's a good fuel for a nuclear reactor. You could hold it in your hand. It wouldn't hurt you. It's a pellet of that, you could hold in your hand.  It's emitting very little radiation, a little tiny pellet. But if you put enough of the pellets together into a fuel rod, and you put a whole bunch of these fuel rods together, you begin to assemble enough of this stuff that the chances of capturing one of these neutrons goes up, you have this chance of sustaining the reaction.

And in fact, you need to slow the neutrons down. And what you do is you run some water around that. If you put water on it and water tends to slow fast neutrons down, it's called a moderator. So that's why these cores are in water. One of the reasons is that the water itself slows down the neutrons. It makes it more likely that they'll participate in the fission of one of these U-238s.

So why isn't a nuclear reactor a bomb? Why doesn't it just all explode at once? Why doesn't it all. fission and explode at once? The answer is that it actually has a negative, what's called a negative coefficient. And a negative coefficient is basically a setting where it is not producing quite enough, immediate neutrons by fission to sustain the reaction. It's got almost that much. And then there are some later on reactions like the breakdown of this nucleus, which itself produces something that, that add a few neutrons that will just carry it over and you can reach a point where you actually have a nice steady state there. You're just below a positive coefficient. You're around one. So that just about every neutron that's going out is causing a fission. But you're just enough under that, that it doesn't get to be a runaway. 

And if you've studied nuclear engineering, it's all about this. It's all about how to figure out that and how to make that work. And it turns out that the reactors are designed so that they have a negative coefficient, except in some places like Chernobyl, where they suddenly had a positive coefficient and the thing blew up.

This is a plant. When you make nuclear fuel, you have to make it out of something. And you make a typically out of uranium oxide. But it's usually something like complex uranium oxide. And to make this stuff, you tend to dissolve it in nitric acid and you get out this stuff, which is uranyl nitrate, and that's a usable fuel for various purposes.

The plant that we were working in was a plant where a lot of these processes go on. They're mostly chemical processes. They're not so much nuclear in the sense that they're not doing the centrifuges there. They're doing chemical separations of these things and preparation of things that are going to be nuclear fuel.

So in goes the raw uranium stuff and various things, and out comes to the uranium that can be a fuel that can go to be used in a nuclear reactor. And it's just a company that does this. It's not a  power company. It's just a company that takes the stuff and does the chemical reactions on this and it gets the chemistry done. And then at the end, you end up with this stuff, which can be a fuel pellet.

Now, you would recognize that they, that the key thing in making this whole system safe is to make sure that either you have... You have to have a bunch of things but the most critical thing is you don't want to have too much of this stuff, because that works with fast neutrons.  So this, you want this to be low, but the other thing is you want the total amount of stuff that you have in any one place to be less than is necessary to have the critical reaction. This is called critical mass below this. You can't get a critical reaction. There isn't enough stuff.

And it turns out that the critical mass for uranium in various kinds of mixture is something around six or seven kilograms, between 12 and 14 pounds. So if you're going to make a bomb with uranium, you'd need about something between eight and 12 pounds of highly enriched stuff. If you want to make a criticality event occur, you need about seven kilos of this combined mix of a different kind of ratio. So the basic rule of avoiding criticality is you're always going to make it so that you have less than seven kilos, or let's say six to be on the safe side. You're always going to have less than six kilograms in one place.

You can have six kilograms spread out in a long line. No problem. You just can't bring it together into a clump. If you put it together in a clump, then it's all there, and all the neutrons that are coming off are able to participate in reactions and bang this stuff up. So you could take six kilograms of highly purified uranium, and just lay it right out here on the table in a long line, nothing bad would happen. 

Take that in your hands, put it together like this, you've got a little bomb. It'll go critical. And when it goes critical, the reaction speeds will suddenly take off and you'll have this huge release of energy, lots and lots of gamma rays, lots of photons, lots of radiation, bad stuff.

Criticality is something these guys don't want. They're not a nuclear reactor, they're a fuel processing plant. They're doing chemistry. So to avoid criticality, basically they have a process that involves two things. One is called the geometry and the other is called mass.  

And the idea of the geometry is just what I told you. You could take your uranium and put it in a long, thin tube like this. And as long as it's in the long thin tube, The geometry isn't going to allow a reaction to take off. But if you put it into a small ball or in the case of plutonium into a pit, I don't know if you've ever seen a picture of these things, but they look like little  hexagonal shapes together, and there's a little tiny thing it's about that big. You start to put it into this. This is a bad geometry. So if you design all your piping and all your tubing and everything made out of these long pieces, the geometry is never going to allow enough uranium to get together, to have a criticality event.

So if you make this all out of, if you make your chemistry stuff all out of long tubes and pipes and pumps and other pipes and long chambers and stuff: Hey! This is great because these don't have a shape... Their geometry is wrong for making a nuclear reaction. 

The other thing is that you have to be careful never to put too much of this stuff together. So, for example, if you have a big pot of this, or a container of this, you want to make sure that there's no more than six kilograms inside that container. The container itself could be very large. A container might contain... now this might contain a hundred liters of uranyl nitrate, but as long as you keep that total amount below six, you're fine, nothing bad's going to happen. Basic, very basic stuff. 

What these guys were doing was essentially processing this stuff, getting it into fuel form. And in the processing that they were doing, they'd been doing this for quite some time, they would take and do the chemistry where they would take this uranium stuff and they'd put it into a solution with some acid. And they turn it into a liquid and then they would pipe this off and you could put this into a long chamber and do what's called solvent extraction, not important, but if you use an organic solvent, you can get some impurities off and then they would take what was left in this. And they would put it into something here and then they would get it out at the end and they would be able to take it and put it into essentially a small container and send that off to whoever's going to use it for fuel. A bunch of steps, pretty straightforward. Something goes in the end, something comes out, some goes in and something comes out and what comes out is valuable and you can sell it. 

The exact details of what you make depend upon what kind of reactor it's going to. If you're sending something to one reactor, it's a different kind of fuel than if you're sending it to another one. The Japanese have multiple different kinds of reactors, including a bunch of research reactors and the reactor business had not been doing very well in Japan. So the numbers of these processing of batches, what they call campaigns, was gradually becoming less. The need for nuclear fuel was going down. They didn't need so many people. They started laying people off. They had longer time between each one of these things. People were involved in some of these processes who'd never done it before, because sometimes years would go by before they would do this again. So there's some long period of time could go by before they would process in a particular way.

One of the problems with what they ended up with was, they ended up with a bunch of little units, each one of them, something on the order of two liters or something like that, containing less than a kilogram of of the radioactive fuel. But remember, they've got to keep these apart. So they don't have any big containers, right? So they keep these things together.

The problem was that each one of these processes would produce a different efficiency in terms of the purifications. Might be 99%, it might be 98, this could be 92. And so what you had is these things coming out, each of which had a different quality to it. So if you were the plant receiving this stuff, you'd have to take a look at each one of these little things and decide what kind of quality fuel it was and change your processes, how much, how many pellets you're going to get on. It's a really bad way of doing things.

(18:55)

So the goal became, we want everything that you produce to us to be at the same
quality level. Now there's two ways you can achieve that. One is you can make
this system so perfect that it always produces 98%. The other way is you can
take whatever you've got here and mix it up and put it back in these little
bottles, but by mixing it, this one gets a little bit of this one gets mixed
with this and becomes a different piece. And this one gets mixed with this and
becomes a different bit. And then these two get mixed together. You can find a
way to essentially mix stuff so that it all gets averaged out. It's basically an
averaging process. You're using the, these amounts, which are, have different
qualities, but you're spreading it out by doing a whole bunch of mixing to make
it so that these things in the end are all the same. That's the whole idea is to
get them all to be the same.

(19:51)

Notice that this is at the end of the process. It's something that you're doing
because it makes your product more attractive. And the rest of the stuff, the
basic physics hasn't changed. It's just a way of selling better materials,
making your customer happy.

Now, somewhere in the five years preceding this event, they had realized that they had here one really big tank. This really big tank was about a half a meter across and almost a meter tall. And this tank was big enough and it had, the other thing was that it had down in it, little propeller on on the end of a motor, which could circulate what's inside the tank. And it also had a water jacket around it. That is a kind of a sleeve around this thing, through which cooling water could be pumped. So you can pump water in here and keep the vessel cool. And they realized that one of the ways that you could take these things and instead of doing this mixing is to actually do something in here. That, is if you poured them in here and just turned on the propeller, it would mix all this stuff together so that it was all one stuff. And then you could take, come out the little spout here at the end and you could fill your little containers and off you go. 

I mean, this sounds funny and you're laughing because it sounds so simple, but it is almost just this simple. It's got a few more steps in it, but it's right about this simple.

So, at about 10:35 in the morning, on this day in 1999, these three guys were in there. Three Japanese guys, two of whom had some experience with this, one who's a brand new guy. And they're taking a bunch of these things and there's a little, actually, the top of this is closed. You couldn't see inside it. It's got a dome on it and there's a little hole in here and they had put a funnel in this and were pouring these things one after another, into the tank. And once they got to about 6.8 or 6.9 kilograms. And by the way, this, because it's here is all together. There was a sudden flash of blue light that came out of this and a sound and a little shaking, and they immediately realized that they had something very wrong. This had never happened before.

And the two guys who, one guy who was pouring and the other guy who was apparently holding the funnel, both got lethal doses of radiation, which is not terribly surprising because this jacket doesn't provide any protection against the radiation. So basically they were sitting on top of a hot nuclear reactor about maybe two and a half feet away from a nuclear chain reaction that's gone critical. And so they had just got burned right down. The guy out here didn't get quite so badly burned. He actually survived. The two guys who were burned right down didn't. That one died. I would think a week later on the other a month later or so after bone marrow transplant that didn't work.

They ran out of the building as fast as they could. There were all sorts of alarms that started to go off. And the Japanese power company there that fuel company spent the rest of the day, along with the Japanese government, trying to figure out what to do. Because once started in this sitting, the reaction is going to continue until it's used up the fuel. But what actually happens very often is that it goes through a series of reactions. It has a prompt reaction where it's doing all this stuff. And then remember some of those particles that came off, they were themselves radioactive and had their own half-lives. And so they would hang around for a little while. And then they would start to decay and they'd add enough neutrons to get the reaction going again. So you could have what looked like a pulsatile chain reaction over time. This is all made worse by the fact that there's this one water jacket around here. The water jacket is acting as a neutron moderator and reflector, and it's taking some of the neutrons which normally would escape right through the walls of the steel container and actually slowing them down and bringing them back in so that the reaction can be continued.

So the Japanese in the first day spent a lot of time figuring out a way to cut this pipe that feeds the water in here. And let all the water drain out of this thing to try and get rid of the, not because they want the water out of there, but they want to stop the chain reaction, which they can do by getting rid of some of the water that's a moderator. And they do that, and then after that they can get this thing cleaned up. Pretty big accident. Not a huge amount of contamination had to evacuate about, I dunno, 350, a thousand people, something like that. The problem partly is that the Japanese build their plants right in the middle of their built-up areas. So this plant was literally, less than a hundred yards away from somebody's house. So you've got this big problem with it's happening all very locally.

This was the biggest Japanese nuclear accident until Fukushima. There were actually two Japanese nuclear accidents before that, but the Japanese had nothing to do with them. They were American-style accidents that were visited on Japan. But after those, this is the first Japanese home-grown accident, if you will. It was very disturbing because the whole idea of this facility was that you didn't have to worry so much about it because it couldn't go critical because it was designed in such a way that was not a problem.

This was not given the same kind of safety consideration as a nuclear power plant or someplace that's dealing with  weapons grade plutonium or something like that, because this was thought to be chemistry. This is chemistry. We're just doing chemistry in here. We're not doing physics, not doing nuclear stuff. We're doing chemistry. And, they were doing chemistry, but it turns out that the chemistry doesn't negate the physics. Chemistry, doesn't say, okay, I'm just chemistry, no physics here. The physics actually was still there. It's just that by the design of the plant and the way they had set up the processes, they never got critical masses together in such a way that they had the right geometry to be become critical. It never had a positive coefficient. And so they never started generating power here, until this day. 

As you can imagine, this caused quite a bit of concern. This is a level four accident. There are five levels of accident that are used by the International Atomic Energy Agency. There are five levels of accident. Chernobyl's a five, Fukushima's a five, this was a four. There aren't many fours. It's pretty rare. Four is a really big deal. This is a really big deal for Japan. And it's really big in a bunch of different ways.

It's big because it's nuclear, which is very sensitive in Japan. It's big because it killed a bunch of people. It's big because it destroyed a processing facility and required a lot of expensive cleanup. And it's big because it's not supposed to happen. This is not supposed to happen. The theory doesn't support this. This is not... This isn't where people go, "Oh yeah, the nuclear reactor melted down. We had a chain reaction and there weren't good...". This is " Wait a minute. We didn't even know that was a possibility! We didn't know that this could happen. How can this happen?" 

This is a place where this isn't supposed to happen. It was a completely different kind of perspective. It was as though it was as though you got wrong legs, wrong sided surgery in, the in the heart room. "Okay, how can that be? There's only one heart. What do you, what are you talking about?" But it would be somebody taking the radial artery out of the wrong side or something like that. But, this was a very big, shocking event. Afterwards... one of the advantages is that we're now in 1999. So we had TMI in 1979. We had Dryden Air Ontario in 1989. We got Tokaimura in 1999. There's exactly 10 years between each one of these events. We went from nuclear to aviation. We're right back to nuclear.

This is not supposed to happen. No one had modeled this. No one had considered what this was like. This was not even on the radar as a possible kind of event. Everybody was concerned about the reactors. Sure. Oh, we got to be careful with those things. Nobody was thinking about this fuel processing. These guys are doing chemistry after all. 

There were a bunch of studies of this that were done afterwards, and some of them are reported in this special issue of Cognition, Technology, and Work. I'll tell you the story of why is. The reason that this special issue comes about is because Erik Hollnagel is good friends with the author of the paper "Actualities need to be captured", Fujita. Erickson. I think Erik's in Norway at the time maybe had been in Sweden already, but I think he was in Norway at the time working at Holden. So he's a nuke. Fujita is a nuke guy from Japan. They know each other and have worked together written stuff together. They get together along with Pietro Cacciabue and a couple of other people who are all nukes. They're all from the old nuke group back 20 years ago. This is a group that started 20 years ago and they go, "Holy cow, we've got an event and it's completely a surprise. We had no idea this was coming. This has come from out of the blue. How did we get into this?"

And so they put together this special issue of Cognition, Technology and Work, and what they basically do is publish the full human factors analysis, which is done by the Japanese guys. And then ask a whole bunch of people for comments on this. 

And so the people they ask are folks like Jim Reason and Andrew Hale who's the big guy in the Dutch world on this stuff. Dave Woods, who's one of the big nuclear people. They make the same list of people who you saw back there after TMI. They're still around. And they go, it's been so long since we've had a big nuclear accident. So these guys go get together. They go around, they get all these guys and they say, write us just something, a couple of pages. We don't care. Basically. We don't care. Just whatever this makes you think of.

And so you get all these kinds of interesting commentaries. Each one is coming out of a completely different area. You looking at me, Ooh, what's that about? What's this? But what you're really getting is all these guys with 20 years of experience looking at accidents and models and all the rest of this stuff now having a chance to look at a fresh accident that happens in a way that no one really thought was possible.

This is a brand new kind of accident. This isn't an old, Oh, the pilot operated relief valve thing opened up and we had problems with understanding where the water level is. This is out of the blue and completely different territory. And that's why you get these interesting things.

Now one of the things that's interesting about this is you get two things. One is that everybody, they all agree that human factors is really important. They all agree that risk and safety are demonstrated here very well. And they all disagree about what to do. There is absolutely no agreement. They do not. What you read through these papers and you look at the papers and you go, wow, that's an interesting perspective. And you turn to the next one and you go, Oh wow, that's a completely different thing. This guy wants me to do some kind of analysis. This guy wants me to do two kinds of analysis. This guy wants me to do three kinds of analysis. And this guy over here wants me to do more work in the safety culture. This guy over here wants me, but it doesn't, it's not like these ideas all coalesce around a single theme. They all agree that the human factors analysis done by the Japanese. Hey, that's a great analysis. That's really good. You guys really figured it out. The problem is not that  they have any trouble on what they agree about. The problem is they disagree about this, about what to do, and in particular, what's next.

There's nothing in this that says the next one's going to be over there or over there. They have demonstrated that in 20 years they become incredibly good at analyzing accidents after they have occurred and incredibly bad at predicting them before they happen. Which means that these guys are in a way at the same time, success and failures. They're successful because after the accident, they don't spend time blaming the operators. They look for the culture and the connections and all the sorts... They don't say, Oh, this operator did the wrong thing. There are still a few people who say, Oh, they should have been following the procedures, but nobody of the commentators says, Oh, you've got to follow the procedures and then everything will be okay. They all say, gee, these guys were working over here, they need to know about the fact that it's designed this way to keep these things from coming together. And, but they also need to have better risk management and they have to have a company that understands and you've got to keep the knowledge around it, and all of this stuff. Lots and lots of that kind of soft stuff. All very positive, all very nice. But none of it really telling you how this is going to happen next time. If anything, what it's saying is all of our ideas about safety and how things work are really excellent at doing these kinds of after- accident analyses, but they're really quite poor at helping us look at the next place that's going to fail.

In fact, this is the history I told you this on the first session, this is the history of safety. Safety is not driven from behind by the desire to be safe. It's being pulled forward by accidents at each turn. Every time there's an accident, you're going to get a whole bunch of safety people who develop a whole bunch of new theories. In fact, there's at least one theory per analyst per accident. And that's a good thing because that theory will explain the accident that you just had. But the problem is it doesn't help you very much with the accident that you're about to have. And the reason to read all these papers is to get a sense both of the great sophistication that's now come into the understanding of accidents and also the kind of sense of futility that there is in having that sophistication, because it doesn't tell you how to fix things.

And a couple of the comments in here are actually quite, I think, quite damning. You have people saying things like ,Fujita says, regulators are not only responsible for framework building, but they're also more responsible for monitoring. That is, he wants the regulators to be involved in looking at what's really going on in the plant. Because these changes, where they were pouring things in and getting stuff... that had started years before.

And you find people like... let me see if I can get the right quote here. You have this comment again from Fujita, he says, I suspect the whole thing started when the regulatory body assumed that 'no criticality accident is possible'. The assumption had pruned ways to impede the accident at the very beginning. That is, the possibility of the accident had been discounted. The regulator looked someplace else and started working on these other things.

The other thing that you'll find in here is that everybody understands that culture and safety is important. There's a paper in here by Meshkati who is one of the guys...  He's a Persian and he does a lot of sort of cultural cross-cultural stuff. And Meshkati will talk about the culture being important. One of the Japanese guys writes, this is a Japanese cultural problem. This is a cultural accident. And indeed, Fukushima turns out to be another cultural accident. But, none of these things give you the sense that you can take that and somehow turn that into something that's going to prevent the accidents from happening. They're all ex post facto analysis.

And indeed, the thing about Tokaimura is that it changes the way we think about where these accidents can happen. It certainly concentrates our attention on other parts of the fuel cycle than just burning it in reactors. But the problem that we see is that  we can't get our minds around how complicated and different the world can be and how the world can change.

One of the problems that Tokaimura brings up is that in the case of TMI where you had this nice plant inside a fixed vessel with a design envelope that was going to allow it to run for about 50 years. This plant is static. It's like concrete, you poured it, you poured all the things, you built the pipes, you've got the core of the reactor, you've got the reactor containment. This thing is pretty well fixed. When you make a model of it, you know what you're modeling. Sure, parts of it can break down, but fundamentally, it's not changing its design very much.

But in Tokaimura, you have this situation where people are figuring out ways to mix up 20 little bottles of things in different and new and inventive ways. There's not much fixed about this world. This world is flexible and changing. It looks, and you'll forgive me for this, but it looks a lot more like the worlds that we live in as healthcare practitioners than this world does.

When people look at the history of safety work and they look at Three Mile Island and things like that, they say, how does that apply to me? This world I live in doesn't look like that. No, it doesn't. It looks like Tokaimura.

 There are these hazards out there, it's possible to give somebody an overdose of chemotherapy. It's possible to give a child an intrathecal injection of vincristine. Those things are possible. But the fact is that doesn't happen for a long time because most of the processes and systems that you have, keep that from happening. But because that risk has been so distanced for so long, and you've seen so few accidents and because things are done differently all the time, because each batch or each job or each campaign is a little different, you can have this situation where once again, you sneak up onto the boundary of safety and that Diane Vaughan sense of normalizing deviance, of accepting this as normal, including this idea about how we're going to do this as normal until pretty soon, you've got yourself a funnel and a big tank, and you're pouring these things into it.

And so Tokaimura is probably a better analogous accident to the kinds of things that we see in healthcare than TMI, not because of the nuclear physics of what's going on, but because this world is just not so tightly controlled and regulated as this one was, and therefore it can change in ways that are hard for us to pick up by doing our routine filing of reports.

And you know this to be true in the healthcare world as well. The healthcare world is described on paper doesn't bear much resemblance to the healthcare world that's operating out there that we come in contact with every day. And so it can easily, I shouldn't say easily, it can drift into situations like this.

Why do we give vincristine and methotrexate at the same sitting in leukemia treatment consolidation therapy? Because the kid's an outpatient. He's not hospitalized. The chemotherapy has worked. We fixed him. He's coming back months later, we're giving him this stuff for those microscopic headmets(?). He's an outpatient. So, we bring him in on one day, we give them both things and he's a scrawling screaming, five-year-old. We've got a couple of people to hold him down and also we'll give him the IV. We get the IV in, we do the LP, we put the stuff in there. We go around, we give them methotrexate on the other side, everybody's done, kid's happy, we send him home. Except that now we've got the methotrexate and the vincristine and syringes on the same back table. (???)  And now it's possible for us when we're doing the LP and the kids squirming, and we're having trouble holding him down. And I'm trying to keep that needle in there to reach back and grab a hold of a syringe of vincristine. A neurotoxin and inject it directly into the intrathecal space rather than the methotrexate that I wanted to put in there because of increasing (?) clinical intravenously. 

The world we live in is so plastic and so variable and has so many different things going on in it that, that the possibility of events like this occurring out there is much higher than it would be if this, the world had this kind of fixed concrete, it's concrete and steel, kind of feeling to it. Because it's not concrete and steel.

When people talk about socio-technical systems very often you will hear people talk about this a lot and they'll talk about power plants as the example. And after a while, the nurses in the audience and the docs in the audience will get so frustrated with the nuclear examples that they will say: Stop it! You're talking about pure technical systems and I live in a socio... capital, SOCIO technical. That's the way they want you to think about it because from our point of view, it's all social, right? It's all about pressures and demands and production and moving back and forth and all this sort of stuff. It's the technical part seems to us to be almost background. It's not really central, it's much more important in fact then than we generally realize. It's much more balanced.

But from hearing people talk about aviation and nuclear power and stuff like that. And then to come into healthcare, it's about the same ideas. People go, Hey, come on. This is a socio technical system. It's the socio part that's causing our problems. I don't think that's really true. I don't think that's a fair critique, but it's a very important one to think about because when you're asked to provide an accident for somebody, to explain safety and you want to deal with safety. You're going to be, you're going to get a lot more mileage out of Tokaimura than you are going to get out of Three Mile Island. You're going to get more mileage out of Dryden than you're going to get out of Three Mile Island. 

Even though the guys who are doing this at every stage along the way, they're the same people. They're dealing with the same things. They're using the same models. They're looking at the same stuff. They're doing it the same way. This is not, it's not like we had this accident and then a whole bunch of new people came along. We had Dryden and then a whole bunch of new people came along and then we had Tokaimura. It's the same guys. It's the same as... Jim Reason is here! Jim Reason's writing in the first person here! In 19...  And actually this comes out in 2000, but I, from 1979, it's the same guys! It's quite remarkable. 

Any questions about Tokaimura before we go on and talk a little bit about the bootstrapping idea? 

I just wonder, I think I, I heard that you'd say that this was a accident that no one could foresee?

 Yes

And that was the difference. One difference between the other accidents that you mentioned. But would you mean that Three Mile Island that anyone could foresee that accident? How. I did not understand...

Anybody who had I don't, the question about foreseeing has a lot to do with what you're looking for. They were not looking for Three Mile Island. Although during Three Mile Island, some of the operators were saying, "holy cow, this is like Davis-Besse again". Because they had that same accident at that Davis-Besse earlier. So the signature of this thing was not entirely unknown to them. And in some sense, to say it's foreseeable is a little different than say that it was foreseen. But, that's different than saying impossible.

And this Tokaimura accident, was an impossible accident. There's an old joke about the the creator of the first English American dictionary Noah Webster having his wife come home and find him coming home to his house and finding his wife in bed with another man. And she says to him, as he walks in the door, she says, you've surprised me. And he says, Madam, you have astonished me. The difference was that she of course knew what was going on. And so she could be surprised by him, but he was astonished. He had never considered this as a possibility.

And the Tokaimura was an astonishment or what some, what Zev Lanir and others have called a fundamental surprise which means a surprise that is fundamental in the sense that until you actually see it, you cannot believe that it is possible. It's one of those "I can't believe this has happened". Not, "Oh, I always knew this was a possibility and I've never seen it before" like your first case of malignant hyperthermia, if you're a an anesthesiologist or something like that. It's where you see something that you just didn't believe was possible. Some people would call it the Black Swan.

## Messy details

Other questions? So now we talk about these three different papers here. There could be a number of other ones because the first paper is the messy details by name and it says it's, that's the introductory paper to this series of special papers. And in the special issue of IEEE SMC if you look for the same issue as the, this paper, you'll see that there are multiple papers in there by different people. The second paper, which is the cognitive artifacts paper. And then the third paper, which is the bootstrapping paper, it's actually a chapter in a book on cognitive task analysis. But there are three papers in there that you can look at. And these are all papers that come out of or are heavily influenced by David Woods because everybody who's working, who's writing in these papers is essentially a Woodsian. They're all people who are Woodsian in their character. And so these are all extensions of Woods's ideas, which after all are extensions of Rasmussen's ideas. So it's all Rasmussen, really. This is all just basically Rasmussen said it all. 

The messy details is a kind of an inversion paper and it says that, and this is an empirical observation, is that when we look at people trying to do cognitive task analysis, we see them get bogged down in unproductive areas. They get bogged down trying to figure out what the cognitive tasks are, or to figure out where to go to look for the cognitive tasks or to figure out what kind of work has cognitive tasks in it. And very often they get caught in the details of a domain, that's so complicated that they spent a lot of time doing very unproductive work.

The big problem with cognitive task analysis, the big risk, the downside risk is that you get lost in the details of the domain. You can see this when a person who doesn't know anything about medicine comes into medicine, and they're trying to start doing some work in the area about cognitive task analysis, but the first thing they have to figure out is why do you have these different colored IVs? And so they have to start there and you have to spend time. We get these different IVs they're different sizes or different sizes because the fluid goes through at different rates. Fluid goes through at different rates because of its physical properties. And we can get more fluid in with the bigger ones, but you want to use a smaller one, a baby, da da da. You have to do this whole thing. And the first day you spent is just about colors of IVs. By the fifth day, the guy is completely against the wall. It's just, " No more! I can't stand it! I'm drowning here!". And so they run out of the building screaming because they're overwhelmed by the details of the domain. And you've seen this.

 The corresponding risk here is is a kind of a, a more upsided risk. It's not quite as bad as failing, getting lost completely. It's going narrow. This is the idea of taking something that is so completely narrow, that you don't have to get caught up in the details of the domain. So instead of looking at the entire vital signs monitor with everything on it and all the rest of this stuff, you study the turning control button that you push and you say, what should the shape or size of this be and how much pressure should you use to push it in? And how fast should it turn and how you, that's the level of study and then you say I don't care about the details of the domain because I'm really down to this level. But what you're really doing is you're getting down almost into that, SRK. Skills rules knowledge. I should put it the other way. KRS, you're getting almost down here, right? It's you're looking at the skill, some psychomotor thing something really very basic because you just say, I can't stand to be in the domain. I don't want to be there. And so I'm going to simplify what it is and I'm looking so far that I don't have to worry about getting bogged down. And this approach here can be summarized as the "go narrow or go home" approach. You either, you, you just it's really an abandonment of cognitive task analysis. It says I can't do it. It's too hard. I can't figure it out. It's just, it drives me crazy. 

 ## Cognitive artifacts

What Nemeth claims in this paper is that this is not the only alternative, that there are productive methods here, but they're not familiar to us. And that the possible gains here are many, and that you can do this, but you need some other methods. And by this, he does not mean experimental methods as much as he does mean varieties of ways of getting inside the cognitive frame. That is again, if you imagine that you have your practitioner, who's looking at a scene and thinking about the scene and what it means. That they have a mental model. What you're trying to do is you're trying to go from looking at this, to looking at this, constructing this. You're trying to understand how it is that the person is understanding what the world is telling him and what he ought to be doing to change that world.

He's got a model of himself in the world. When you're cracking the cognitive task analysis, you're doing something about getting insight here. That's where you want to be. And he's got some suggestions and some methods here about doing that. He also points out many of the features of the domain that makes it difficult to do this.

And in fact, the reason that you have these problems here is because of the domain characteristics. That is the domain characteristics make these things dangerous. The domain is really so rich, there's so many different things can happen. There's so much complex knowledge. There's so many interleaving factors and competing factors, but it is actually very hard to study. The domain characteristics make it difficult to study. But some of those domain characteristics, you can actually exploit to get inside this. And that's what he's trying to show you with cognitive artifacts. 

And if we, if you're going to pick the one best, most reliable way to get inside a domain it's to look at the artifacts. This is now Richard talking, not the literature, but basically the idea here is. That humans are makers of artifacts. They make tools like  flint and they use it to make a rock hammer and that's an artifact, right? A rock hammers is an artifact. It's a tool for doing something. That's what we mean by artifact. If you're an anthropologist and you go out into the world, you look for artifacts.

And some of the artifacts that you find are nothing more than a piece of flint with a couple of things scraped off of it. But that's an artifact. Some of the tools are very simple and, but there's a long line of these things in, and the thing that really sets humans apart from other people is that the development of new artifacts that improve on the old ones. Other animals use artifacts, but they don't refine them to create whole new classes of artifacts based upon their experience with early ones.

There are birds that can use a twig to get the little grubs out of the tree so they can eat them. But the birds aren't smart enough to say, Oh, what I need to do is start shaping some of these twigs so that they have exactly the right size and carry them around with me, so I don't have to go hunt for one. That's not bird-like but that is people-like. These are artifacts. They're physical artifacts. Cognitive artifacts, the earliest ones are those little drawings and tablets that you see. You've seen these clay tablets with the little pressure things in them. Those are cognitive artifacts, right? These are, if you look at the Sumerian stuff, they got little things in them. They'll have a little clay tablets about this big, and it was a piece of clay that they pushed a little lines into. That was a recording thing. It turns out that this is all accounting stuff, it's, this is all Joe owes Bob five sheep. It's that kind of level of detail. That's what's in these tablets, it's all accounting. 

But that's a cognitive artifact as are pictures and diagrams and all those sort of things. They're cognitive artifacts because their meaning that ...their meaning as an artifact is not contained in the physical body of this thing, the fact that it's made out of clay or the fact that the indentations in the clay, that's not what matters. The fact is that this has some sort of symbolic language that is being used to express some other idea. Some other representation of something else that is out there in the world.

There's some sort of symbolic function here that represents the five sheep that Joe owes Bob. And we don't have any trouble understanding that this is representing the idea of five sheep. But that's what makes this a cognitive artifact, because it represents something for us in our own cognition. 

Cognitive artifacts are ubiquitous. They are present throughout the world. They are at least as common as physical artifacts. In some cases, more common. The most obvious cognitive artifacts that we have are things like books, and books are very old. And other kinds of things that contain collections of symbols that are very old, very useful and essentially much of what we consider to be knowledge and representation. These are cognitive artifacts. Books are cognitive artifacts. There are ways of storing these kinds of things.

But the cognitive artifacts that we're interested in are not the books, but rather the things that people make themselves in the course of their ordinary work to allow them to accomplish that work. And so let me give you a list of the kind of cognitive artifacts that I think really matter. The first one is, and I don't know if this is true in Sweden, but it's certainly true in the United States. If you go into an ICU, one of the things that you will see there in the ICU is a tray table. Looks like this, got little wheels on it. That's supposed to be meant for holding patient food, but since the patients aren't eating in the ICU, we don't have to feed them off of these things. And on this, you will see the paper chart, if there is one, or the mechanical chart. And over here, you will see a big piece of white adhesive tape that has been stretched out four inch wide white adhesive tape That's been stretched out and put on here. It's got a list of a whole bunch of things that the nurses written on it in pen or magic marker, which is the list of things to do today for this patient. This is nursing language for, "this is what I have to do today". And you will see this in virtually every ICU that you will go to somewhere there is this list. Most of the time it's on four inch wide adhesive tape, which is why that tape is always so hard to find in ICUs because that's what gets used first. Nobody uses half inch wide adhesive tape for this. It doesn't work or it'll be on in some little spiral notebook that the nurse keeps, or it will be sometimes written in notes in the back of the hand. People do this ... they do that, they write on themselves! They become walking, cognitive artifacts. But it's true! But all of these ways of dealing with this are essentially means of building symbolic representations of states of the world. That is, data or items that are out there, plans, and references, and especially long lists of things. We in the medical world love lists. We use them all the time. It's one of the reasons why the checklist idea is the idea of springing the checklist idea on us in medicine is such an odd sort of idea, because we've been doing this now since, at  least the time of Sir Arthur Conan Doyle.

 But all of these things are themselves, not the thing at hand, they're not. The actual hematocrit or the actual reservation to do something or the actual things that are on the list. They're representations of those. They represent. In English, it can be thought of as re presenting, that is, doing it again, presenting again a symbolic record of these different things.

And what Nemeth is trying to show you is that these things are actually, if you can get a hold of them, these things are actually very meaningful. There's a huge amount of meaning in these that it's takes time and effort to make these things. And people do not make them just to make them. They make them because they need to store that information, that symbolic representation is useful for them in the future. It allows them to have this external representation in the world of something that was in their head, but that they now don't have to keep there because it's out in the world for them.

What Nemeth is saying is if you keep track of how people put things into this collection, and what they're putting in here, you will find that these things point specifically to various things in the world. That is there's a representation of the world, a symbolic representation that is actually something that a condition or a state that is meaningful to the operator at some later time.

The reason people write stuff down is not to write stuff down. I'm not talking about the journal or the patient record. That stuff, that's garbage, that's not a cognitive artifact. That is a, that's a red herring. That's a misleading thing. Don't worry about that. People fill that out to stay in good with the authorities. Mostly.

But I'm talking about the little things, these little lists, the three by five cards, the notes that are made in the iPhone, the thing that you write on sometimes you'll write it on your scrub leg or something like that. Those are cognitive artifacts and we use those things to hold information so that later on, as time goes by when we have all thought about this out here and made a reference to it and put it up in our minds, like this, that we don't have to maintain that link because the world is requiring our attention to do other things. We forget about all this stuff. But later on, if we come out here and look at, and we see that something is in a different condition, we can go back and using our representation of this, our cognitive artifact that we have made. We can look at this out here. And we can see that. In fact, the world has changed in some way. It's a way of storing our memories. It's a way of organizing collections of information that are too large for us to hold in memory to show it. And in particular showing relationships, a lot of it is not just lists, but it's ordered lists or scheduled lists. For example, nurses tend to write things down in chronological order because they make a plan for the day. They say, okay, so first we're going to have rounds. Then the guys are going to put a line in. Then I'm going to do the bath. Then I'm going to do this. Then they've got a, they've got a plan for the whole day. They write that plan down. They write it right down there. Okay. 

What's the third word,I can't read it. 

References re presentation States plans, references lists other things as well. Drawings, charts, all sorts of stuff. But the plain fact of the matter is that if you watch any sufficiently complicated activity, you're going to see people putting together and making cognitive artifacts for their own use for later. So if it gets to be handoff time at the end of the day, does the nurse actually sit down and go through the journal record, the patient's record, page by page trying on what's in there? No, she picks up her card or a notebook and she says, this is what we did. This is what we did. We did this and this, Because that's something that is made for purpose. We write that down because it's what we need.

And so what we are really saying when we're making these cognitive artifacts is, we are saying there's the state of the world that matters to me. And therefore, if we can trace both the creation and the later use of these cognitive artifacts, when people are looking at the world and seeing that it has changed and trying to figure that out, if we can see both the creation and the use of these cognitive artifacts.

We have an opportunity to make some claims about what's going on inside the cognition of the operator. That is, we don't get to chop the head off and look at the brain and see what they're thinking, but we can see that they made this and they used it later. And the information in here is information about this world that they're operating in. And therefore we can say this is a symbolic representation that they use. 

It's a very powerful tool, especially in worlds that are very busy. The busier the world you're in the higher, the tempo of operations, the more the cost of doing this sort of stuff, which means that if you're doing it in a high busy, in a very busy world, it must be really important. It's not that when things get busy, people stop doing this. No, not at all. And key. In fact, in some cases, when people get busy, they become very particular about doing this because stuff is going by them so fast that they know they won't be able to keep track of it. When you get into that very high tempo operation and people are still doing this, you are getting a map of exactly what it is that they're paying attention to at that moment. And also a clear indication that this is really important. We don't waste time on writing down the patient's date of birth or the names of all the family, unless we're going to call the family and we want to tell the missus that he's dying, but not tell his mother who's also another Mrs. They have different last names. So we're going to make sure that we're talking to them. Then we will write that down. Make sure to talk to Mrs. Not his mother.

So the idea here is that the people in their ordinary work during the day are doing things to externalize their cognitive processes into the world. So that later they can retrieve them in various fashions and use them in different ways.

And if we can be present and observe how this is happening, we have a chance to at least pin down a couple of places and to see whether or not these things are functioning in particular ways. That is, we can't see the cognition in people's minds, but we can see the externalizations of writing things down, checking things off, turning things over, lining things, up, taping things in places, tearing stuff up and throwing away. We can see all that stuff and we can even see them stop at the moment and go through their book until they find the page that they're interested in. We know that whatever it was that they were looking for is on that page.

So artifacts in a sense map the world, they are a way of mapping. They provide us a ready-made map. They're not really ready made, because they're made to order. They're made for purpose, a ready-made map of the world of... that the operator is dealing with in their cognition.

And in a funny way, I'm very glad that the electronic medical record is so bad because if it was so good and it captured all this stuff, we wouldn't have them doing this. And there would be no more traces that we would have of them doing this stuff. So we couldn't use this technique. But never fear. The record is getting better so slowly that you'll be able to use this technique for the rest of your natural lives.

There's another way in which this works though, and Nemeth in his paper is talking about this other way, which is that one of the consequences of making public symbolic representations.... one of the consequences of making public symbolic representations is that other people can see them too. And so some of these artifacts become shared representations. That is, they may not have meaning only for the person who made them. They may have meaning for other people as well. And this is especially true for things that you write down in public places, like things that are written on the roll around table, on the piece of tape, or things that are written on whiteboards like this cognitive artifact. It becomes a mechanism by which you can share things with other people. 

This shared symbolic representation in the real world, we call distributed cognition. That is cognition is now being distributed from one person to another, so that these representations become something more than just an aid to my memory. They also become a representation, if I have created it, of how I see the world that you can look at. And if my model of the world corresponds to yours, then the information is valuable. And even better, if our models of the world do not correspond. That is, if I look at if I have somebody look at my representation of what's going on in the world  and they see the representation and there that doesn't fit with their representation of what's going on in the world, there's a dissonance there, a disagreement, which allows us to say, "Hey, wait a minute. You just wrote down anceph for this guy. But the guy  is allergic to cephalosporins, do you want to give him something else?"

If you're just thinking cephalosporin, I'm writing ..., I'm going to give the guy a cephalosporin, but you don't write anything down. There's no way for the person standing next to you to observe that behavior. But if you, and those of you who are nurses will recognize that 90% of your work is standing around watching physicians make mistakes and correcting them.

But if you, if your job is in some ways to keep track of what's going on in the world and check to make sure that in fact other people's reflections and representations of the world are the same as yours. Or if there's a discrepancy that yours is updated in a way that brings them into combination. You're not sure which just by looking at this, but over time, this is how you resolve the world. By the way, when people talk about making sense, this is what they're talking about.

It's this process of understanding what's in the world in a symbolic sort of way, and being able to compare that to your own symbolic understanding of how the world works and seeing that those two work together to give you a picture of the situation. And what is interesting is for the thing that's the big trigger here is not when you all have the same idea, it's when you have different ideas.

People keep talking about communication in the operating room. They say, we need more communication in the operating room. I disagree. Communication in the operating room only happens when people don't agree about what's going on in the operating room. If we all agree, nobody has to talk. We can talk about baseball or soccer or anything you want. When we start talking about "what procedure is this?", something's really wrong. When someone says, "What procedure are you doing?" something really bad has happened. If you hear that in the operating room, you better find a better surgeon and an anesthesiologist. Don't work with those people. If you have somebody say,"what procedure are you doing?", you're in the wrong room. But so long as nobody's talking, probably everything is fine because if you keep looking at these two and they look the same, there's no reason to say, what are you doing? Why is it this way? So one of the things that this kind of artifacts in the world, these symbolic representations that we are building work for us is because they become these external representations that are visible to other people. 

That is, we not only make these for ourselves, we make these in hopes that other people will use them. And the place that you can see this most clearly, and that Nemeth talks about extensively in his paper is in the operating room schedule board.

You go to the operating room schedule board. You will be able to see this is a cognitive artifact. It's an external symbolic representation of a plan and a status.  It tells you about the state of the world, what's going on in all these operating rooms right now. And the plans who's next. Who's going to be the next procedure.

 And interestingly enough, people are very particular about the control of this document. It is not that you could, if you've got one of these on a whiteboard someplace, and you just, as an outsider come by and you try to erase something and write something in, you are going to get slammed by the head nurse so fast, it'll make your head spin. They will absolutely. In many cases, they just don't leave markers near the board. They don't leave markers or erasers near the board because you are not allowed to touch them. I have the marker. I am in charge. That's how important the artifact is. The artifact in fact has an almost religious quality.

The other thing that I will tell you that is interesting is that I have seen places that have no functioning medical equipment whatsoever. There's no electricity, there's no running water. There's nothing, but they have an operating room board with cases listed on it. In Afghanistan, there are pictures of a native hospital in Afghanistan. They have no water, they have no electricity. They have almost no drugs or medicines. And yet they've got an operating room board with a list of scheduled patients on it. That's how important that artifact is. And everyone who looks at the artifact recognizes that there's a lot of work to do in room three today. Everybody gets it. It's a shared representation of the world. This becomes in effect the operating rooms. It's not just a symbolic representation. It is the representation. It is the state of the world. It's a reflection of the state of the world. And if we find people arguing about this surgeon says, I really want this case to finish quick. It's not, it's going very long. Could you take this case and move this over to room four for me, please? When you hear that kind of stuff, they're doing symbolic activities that are related to this, which is going on in their heads at the time. This externalization of reference and the communications that surround it, become a basis for making all sorts of claims about the cognitive functioning of the people in that world.

Now it's limited. Also, it doesn't means that you can't say a lot of things about cognitive functions. Like I can't look at a radiologist and say, Oh, how did you know that was pneumonia? Because there's no external representation that he makes of pneumonia. But I'm not really interested in that anyhow, I really am interested in how the operating room works.

And if you look at Chris Nemeth's doctoral dissertation or the paper that's this cognitive artifacts paper, you'll see that not only are there cognitive artifacts, but there are a whole bunch of them. There's schedules and lists and planning documents, and a whole bunch of stuff that all go together to create something which is called the master schedule.

And that the creation of this artifact is in fact, a very important job that's done the day before the operations by a very senior person who knows what he's doing. And so studying this sequence of things can tell you a great deal about what actually goes into creating this and why it has this shape and form. And that's what Nemeth shows you. That's what this paper is all about. It's about how do you use cognitive artifacts as a way into this complex world that is hard to study otherwise? So our rule of thumb is when you start to do cognitive analysis and you don't know what to analyze because you can't get inside the head. You don't know where do I look? How do I understand what it means to talk about safety or how do I understand what it means to talk about communication or something like that? Stop. You can't get at this stuff by sawing off the head and looking inside. There's no little dotted line here. There is no little dotted line. You cannot. There's no little line that says "cut here".  It doesn't exist. You can't do that. So you have to find some other way. And then this turns out to be one of them. 

## Bootstrapping

This leads to the third paper, which is Potter's bootstrapping paper. And the key in bootstrapping paper is that you do this a little bit at a time, that the process is really iterative. You don't sit down and do a cognitive task analysis. What you do is you try to do a little chunk of it to figure out some little bit, and you use that to phrase a bunch of questions that you can then look at further out. It's as though you were looking at one of these lists and saying what's on the list? what are the things that are on the list that he could be thinking about? Ah, he was thinking about drugs. There's a whole bunch of drugs here. The drugs are on the list. Or it's a bunch of procedures where there are other patient names, but whatever it is, it's what that person is doing. That gives you a first shot at going on and saying, okay, what are the symbolic representations that are in that person's head and how are they going to work?

Potter also makes another point, which is that you start out with some very simple kinds of stuff and you gradually over time your cognitive analysis gets wider and wider. And that what you're really doing in this process is essentially starting from zero and then banging back and forth across the world and a bunch of different kinds of studies until you feel like you've gotten something that actually characterizes the world.

But also that, that this is two sides of this picture that, that on the one side, this is the view of the person or the operator, the person centered view. What tasks this person has. And the other side of this is something about how the world works and how the world is behave, what the world is doing that creates these tasks for this person. What is going on in the outside world, and you're really bouncing back and forth between a person's view, the operator's view of what's going on and what is actually happening in the world. And so the other thing that makes it nice is to have a lot of artifacts in the world that keep that the operators are using. So cognitive artifacts includes also things like monitoring screens with data on them, computer charts, physical charts, physical devices. Anesthesia bellows, for example, these are all functional things. They have a function in the world, but they also serve as cognitive artifacts. You can look at the bellows going up and down and that, that means that there's gas going in and out of the patient. Because it's manufactured, so that thing is symbolic. And one of the bad things about the new anesthesia machines, for those of us who practice in the real world is you can't see it anymore. They hid it inside. And so you can no longer see what's going on. Very distressing for an old anesthesiologist, very distressing to have that physical representation taken away.

There used to be there used to be blood pressure, automated blood pressure cuff that made a sound when it was pumping up it went prrrrrrr. And then, as it was deflating, it would go tck, tck, tck, khhhh and you knew when it went khhhh to look up and see the numbers on the screen because of that sound. So you didn't have to look and you didn't have to start the pump. You'd say wonder what the blood pressure is. You'd hear it going prrrrr and you say, Oh, okay I'm going to have a blood pressure in a minute. You can keep doing what you're doing.

And then a little bit later, it will go khhh. And you'd look up and you'd see what the blood pressure was. Now, they're silent. You have no idea when the blood pressure is coming. So what have they done? They built a little beep into the box that tells you that the measurement has finished. Actually the blood pressure measurement, when it gets done, it goes beep and it tells you that it's done. But previously that wasn't, that was a, an artifact. There's another sense of the term of the way the physical world worked, that we relied on. 

Woods tells a wonderful story in one of his papers about replacing the old display in a nuclear power plant, which had these kinds of things that you used to see in railroad stations where the letters would turn over, and then it would show you this, the name of the train, and now they're electronic, right? And so they had a control room where the positions of all the control rods were shown individually by these things that made a map of the top of the thing. When you started to pull one of the handles that control the control rods, you could hear it go prrrrr. And that's how you knew that something was happening.

They replaced it with an electronic screen that didn't make any noise. And all of a sudden people couldn't operate the reactor as smoothly because they no longer had that little audible cue. Nobody intended for that cue to be meaningful, but it became a cognitive artifact in the world that was actually very useful for people and help them coordinate their activities.

If you want to understand the world, you start out with cognitive artifacts. That's my best advice to you. And you start out in some small place and you do a little study and then you do something else in another study, more focused on how people are using the data. And then you go back to the world and you look and see how it changes and various other results.

And you keep doing a series of studies using a variety of different techniques, some of which Potter talks about, and then you're ready to go onto the second half. Which is trying to use these results to create some sort of aid and this making of an aid that is making a new cognitive artifact that will help people. All of the things that you plan to do to help people by the way, are cognitive artifacts. So, when you get around to doing this aid, it becomes a test of how well you have done these parts, as you look at the aid in use here using the same techniques that you did before.  But you now look at the aid and this, and you use the aid as a way of knowing that you've actually done the result, you've done the studies correctly. If your  model of what is going on is correct. And the aid that you built will help if you put the aid there and it helps people. That's confirmation that the cognitive task analysis that you did here was actually useful. 

I see we're coming to the end of our time together. So we'll call it quits there, unless there are some questions. Thank you very much. .